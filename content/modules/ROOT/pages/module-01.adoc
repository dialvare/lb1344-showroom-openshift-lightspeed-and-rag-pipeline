= OpenShift Lightspeed Basics

OpenShift Lightspeed uses a natural language interface to allow users to ask
questions. You have used many chat interfaces before, so OpenShift Lightspeed 
should feel very comfortable to use.

OpenShift Lightspeed is designed only to answer OpenShift-related questions, and
it will generally attempt to reject questions that are unrelated to OpenShift 
and Kubernetes. If you try hard enough, you can probably get it to do something
it wasn't explicitly designed to do, but this is a shortcoming of all
non-deterministic language-model-based systems. It is a bit of a game of 
whack-a-mole trying to keep up with all of the possible negative outcomes, and
trying to prevent them is a topic of active PhD research right now. If you see
something bad, be sure to report it using the feedback feature. We will always
do our best to improve the quality and safety of the system.

== Starter Question

Log into the OpenShift web console by clicking the link:

{openshift_cluster_console_url}[OpenShift Console,window=_blank]

Username:
[source,role="execute",subs=attributes+]
----
{openshift_cluster_admin_username}
----

Password:
[source,role="execute",subs=attributes+]
----
{openshift_cluster_admin_password}
----

Once you have logged-in, you should see the OpenShift Lightspeed button in the
bottom-right corner of the OpenShift console:

image::ols-icon.png[]

Click the button, and it will open the chat interface:

image::ols-interface.png[]

Why don't you start out by asking an easy question like:

[source,role="execute",subs=attributes+]
----
How do I configure a horizontal pod autoscaler?
----

OpenShift Lightspeed should provide a detailed answer about how to do it. And,
if you scroll to the bottom of the chat window, you will see that OpenShift 
Lightspeed has also provided a link to the documentation that was used to 
generate its response:

image::related-docs.png[]

== Troubleshooting Question

In your environment there is a pod that is failing to schedule for some reason.
In the OpenShift console, click _Workloads_ on the left, then _Pods_, and then
make sure to select the project named `broken` from the dropdown at the top of
the page:

image::broken-project-select.png[]

Now, in the pod list, click on the one pod which you can see is in the _Pending_
state.

If you closed the OpenShift Lightspeed window, re-open it. Make sure to click
the _Clear Chat_ button in the OpenShift Lightspeed interface.  Then, click the 
_+_ button to attach information. In this case, as this pod is currently
_Pending_, there are no logs we can attach, and we don't really care about the 
events, either. Go ahead and attach the _Filtered YAML_, which will include the
status information for this pod. 

image::attach-button.png[]

Then, simply ask:

[source,role="execute",subs=attributes+]
----
What's wrong with this pod?
----

You should get some detailed information about nodes and node selectors. 

Now go ahead and attach the complete YAML, and then simply ask:

[source,role="execute",subs=attributes+]
----
Can you fix it?
----

Fortunately, this is a pretty obvious typo: `worker` is spelled wrong. And,
GPT-4o is a very capable model, so it suggests that this typo might be the
problem, and suggests some ways for you to fix it.

Can you see how the simple act of attaching details to your request can 
dramatically improve troubleshooting outcomes? 

Note that you can attach multiple things to your request at the same time, like
a service, a route, and a deployment. This can make more complicated
troubleshooting scenarios easier.

== Cluster Interaction

The Cluster Interaction feature allows OpenShift Lightspeed to interact and gather information from your OpenShift cluster in a read-only manner. This enables the LLM to generate highly customized responses for your environment.

NOTE: This is currently a Technology Preview feature of OpenShift Lightspeed.

OpenShift Lightspeed includes an MCP server already preconfigured to communicate with the OpenShift API. This server provides some built-in tools, such as _oc_get_, _oc_describe_, _oc_logs_, etc. When the cluster interaction flag is enabled, the model may choose to call one of those tools to retrieve relevant information directly from the cluster to support your query. All tool usage is performed using the user's own credentials and access rights, preventing any privilege escalation.

Cluster Interaction is enabled in our environment, so you can try asking some questions about cluster resources and see how OpenShift Lightspeed responds. For example, you can ask:

[source,role="execute",subs=attributes+]
----
What are the pods in the openshift-lightspeed namespace?
----

The GPT-4o model likely chose to use the _oc_get_ tool to retrieve pod information from the `openshift-lightspeed` namespace. You can view the tool's output by clicking the **oc_get** button displayed after the response. This information was used by the model to generate the final answer containing the list of all pods in that namespace.

== Problem!

Remember that first question you asked about pod autoscalers? Well, you should
know that at ACME Corp, pod autoscalers are not allowed to be used by default,
and that there is a special process for enabling autoscaling. Continue
to the next section of the lab to learn how you can add your own organizational
knowledge, documentation, and policy information to OpenShift Lightspeed.
